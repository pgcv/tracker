# -*- coding: utf-8 -*-
"""try_ssd_person.ipynb

Automatically generated by Colaboratory.

Original file is located at
	https://colab.research.google.com/drive/1DhHZXMBrd6GG6WgauTr62AaVl-LGBQN9
"""

import torch
from torch.autograd import Variable
import cv2
from ssdtracker.data import BaseTransform, VOC_CLASSES as labelmap
from ssdtracker.ssd import build_ssd
import imageio
import matplotlib.pyplot as plt
import time
import numpy as np
import sys
from ssdtracker.sort import *

# %matplotlib inline

device = torch.device("cuda")
torch.set_default_tensor_type('torch.cuda.FloatTensor')

class Det():

	def __init__(self):

		self.net = build_ssd('test',300,2).cuda()
		self.net.load_state_dict(torch.load('ssdtracker/weights/ssd_person.pth'))

		self.transform = BaseTransform(self.net.size, (104/256.0, 117/256.0, 123/256.0))

		self.COLORS = np.random.rand(32,3)*256
		self.FONT = cv2.FONT_HERSHEY_PLAIN
		self.count = 0

	def process_image(self,image,mot_tracker):
		height, width = image.shape[:2]
		x = torch.from_numpy(self.transform(image)[0]).permute(2, 0, 1)
		x = Variable(x.unsqueeze(0))
		x = x.cuda()
		
		y = self.net(x)
		
		detections = y.data
		scale = torch.Tensor([width-width*.025, height-height*.05, width+width*.025, height+height*.05])
		
		allbox = []
		for i in range(detections.size(2)):
			if detections[0, 1, i, 0] >= .3:
				pt = (detections[0, 1, i, 1:] * scale).cpu().numpy()
				bbox = np.append(pt, (detections[0, 1, i, 0]).cpu().numpy())
				allbox.append(bbox)
		
		allbbox = np.array(allbox)
		track_bbs_ids = mot_tracker.update(allbbox)   

		for d in track_bbs_ids:
			color = self.COLORS[int(d[4])%31]
			cv2.rectangle(image,(int(d[0]), int(d[1])),(int(d[2]),int(d[3])), color, 2)
			cv2.putText(image, (str(int(d[4]))), (int((d[0])), int(d[1])), self.FONT, 1.5, (255,255,255), 1, cv2.LINE_AA)
		
		return(image)

	def process_video(self,video):

		#extract the video info and load
		name = video.split('/')
		name = name[len(name)-1]
		ext = name.split('.')[1]
		name = name.split('.')[0]
		cap = cv2.VideoCapture(video)
		fps = int(cap.get(5))
		frame_count = int(cap.get(7))
		print("Total time: ",time.strftime("%H:%M:%S", time.gmtime(frame_count/fps)))

		if not os.path.exists('output'):
			os.makedirs('output')

		#Resizing the video
		h, w = int(cap.get(3)), int(cap.get(4))
		height = int(h/2 if h>400 else h)
		r = height / h
		width = int(w * r)

		#Writer to write the video
		writer = cv2.VideoWriter('output/'+name+'.mp4', cv2.VideoWriter_fourcc(*"mp4v"), fps,(height, width))
		i=1
		start = time.time()
		mot_tracker = Sort()
		while(cap.isOpened()):
			ret, frame = cap.read()
			if ret==True:
				frame = cv2.resize(frame, (int(height), int(width)))
				frame = self.process_image(frame, mot_tracker)
				writer.write(frame)
				
				#FPS and time updater
				fps = i/(time.time()-start)
				remain = time.strftime("%H:%M:%S", time.gmtime((frame_count-i)/fps))
				sys.stdout.write('\rTime Remaining: '+str(remain)+'\tFPS = %.2f'%fps)
				#print("FPS: %.2f"%fps,"\tTime Remaining: ",remain,end='\r')
				i=i+1
			else:
				break
		cap.release()
		print("\nDone! and saved to {}".format('output/'+name+'.mp4'))
		writer.release()

#process_video('max','mp4')

